# Проект - Анализ рынка валют

Общая задача: создать ETL-процесс формирования витрин данных для анализа изменений курса валют.

Подробное описание задачи:

Разработать скрипты загрузки данных в 2-х режимах:
-  Инициализирующий – загрузка полного слепка данных источника
-  Инкрементальный – загрузка дельты данных за прошедшие сутки

Организовать правильную структуру хранения данных

- Сырой слой данных
- Промежуточный слой
- Слой витрин

В качестве результата работы программного продукта необходимо написать скрипт, который формирует витрину данных следующего содержания

- Суррогатный ключ категории
- Название валюты
- Суммарный объем торгов за последние сутки
- Курс валюты на момент открытия торгов для данных суток
- Курс валюты на момент закрытия торгов для данных суток
- Разница(в %) курса с момента открытия до момента закрытия торгов для данных суток
- Минимальный временной интервал, на котором был зафиксирован самый крупный объем торгов для данных суток
- Минимальный временной интервал, на котором был зафиксирован максимальный курс для данных суток
- Минимальный временной интервал, на котором был зафиксирован минимальный курс торгов для данных суток

Дополнение:

В качестве основы витрины необходимо выбрать 5-10 различных валют или акций компаний.

Источники:

https://www.alphavantage.co/

# Реализация
**Выбор архитектуры и технологий**

В качестве исходных данных имеем:
- данные загружаются в формате csv и содержат табличные значения финансовых инструментов,
- загрузка массивных начальных данных происходит один раз, а далее каждый день подгружаются появившиеся новые значения,
- обработка данных происходит один раз в сутки,
- используется максимум 10 отслеживаемых финансовых инструментов 
- размер сохраняемых сырых данных, по предварительным оценкам, не превысит в обозримом будущем 100 ГБ

Исходя из этих данных, разумно выбрать следующую архитектуру:
- одиночный сервер с локальным хранилищем для загрузки и первичной обработки данных. Для большей сохранности данных рекомендуется подключить внешне хранилище для бекапа.
- база данных, развернутая на этом же сервере, но рекомендуется вынести ее на отдельный сервер.

**В качестве решения использовались:**

Локальный сервер:
8 ядерный процессор intel core i7,
8 ГБ оперативной памяти,
120 ГБ диск,
OS: Ubuntu 22.04 LTS

База данных:
IBM Db2 on Cloud

IDE: jupyter notebook,
Язык программирования: Phyton 3.9

[![Схема архитектуры](http://media5.cdnbase.com/media/uploads/file-2/schem1.png "Схема архитектуры")](http://media5.cdnbase.com/media/uploads/file-2/schem1.png "Схема архитектуры")

**Обоснование выбора**

Данная конфигурация:
соответствует рекомендациям по построению хранилищ данных,
имеет запас по ресурсу для выполнения поставленной задачи, 
может быть легко маштабирована добавлением дополнительных серверов,  хранилищ данных, увеличением облачных ресурсов. 
Язык программирования Phyton - современный, широко используемый иструмент для работы с данными. 

**Программная реализация проекта**

Первичная загрузка данных

1. Список финансовых инструментов

В БД создается таблица финансовых инструментов, для которых будет происходить процесс сбора и обработки информации. Таблица сохраняется в csv файл для бекапа. 

2. ETL процесс

Суть ETL процесса представлена на рисунке
[![ETL process](http://media5.cdnbase.com/media/uploads/file-2/ETL-process.png "ETL process")](http://media5.cdnbase.com/media/uploads/file-2/ETL-process.png "ETL process")
 
	2.1. Извлечения данных
	
Загружаются по API данные для заданных финансовых инструментов. Данные сохраняются в csv файл на диск. Оттуда они загружаются во фрейм с данными для проверки и трансформации.

	2.2. Проверка и трансформация данных
Над данными проводятся действия:
Проверяются  на корректность. 
Обогащаются добавлением тиккера для идентификации.
Приводятся к правильному значению названия и типы данных.

	2.3. Загрузка данных
Обработанные данные загружаются в базу данных

	2.4. Проверка данных
Проводится проверка конечных данных, сохраненных в БД.

**Инкрементная загрузка данных**

Запуск происходит через задачу в Cron.
Каждый будний день в 4:01 утра происходит загрузка по API фиксированного блока данных за несколько  последних дней. 
Над этим блоком проводятся ранее описанные действия, но  помимо этого добавляется:
- Проверка блока на наличие ранее полученных данных.
- Удаление их перед добавлением в БД.

**Формирование витрин**

Для формирования витрин используется sql скрипт, который:
- формирует таблицу с данными за прошлый день для выбранного инструмента,
- из этой таблицы формирует новую, где собирает необходимые для витрины значения,
- объединяет таблицы с финансовыми инструментами и значениями для витрины,
На выходе получается витрина, содержащая заданные параметры финансового инструмента.

ER диаграмма  
[![ER diagram](http://media5.cdnbase.com/media/uploads/file-2/ER-diagram1.png "ER diagram")](http://media5.cdnbase.com/media/uploads/file-2/ER-diagram1.png "ER diagram")

Витрина инструментов  
[![data mart](http://media5.cdnbase.com/media/uploads/file-2/data_mart.jpg "data mart")](http://media5.cdnbase.com/media/uploads/file-2/data_mart.jpg "data mart")
